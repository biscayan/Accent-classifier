{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "\n",
    "def data_path(loc, directory, filename, numbering, format):\n",
    "    delimiter = '/'\n",
    "    path = ( loc + delimiter + directory + delimiter +\n",
    "           filename + numbering + format)\n",
    "    return path\n",
    "\n",
    "#train_path=\"C:/git/download/Accented speech recognition/Accent-Classifier/data/train\"\n",
    "#train_path=\"C:/git/download/Accented speech recognition/Accent-Classifier/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction \n",
    "\n",
    "def wav_to_mfcc(file):\n",
    "    sig,rate=librosa.load(file)\n",
    "    return sig, rate\n",
    "\n",
    "def downsampling(file,outrate=8000):\n",
    "    sig,rate=librosa.load(file)\n",
    "    float_sig=np.array(sig,dtype=float)\n",
    "    down_sig = librosa.core.resample(float_sig, rate, outrate, scale=True)\n",
    "    return down_sig\n",
    "\n",
    "def normalization(file,n_samps=240000):\n",
    "    down_sig= downsampling(file)\n",
    "    normed_sig = librosa.util.fix_length(down_sig, n_samps)\n",
    "    normed_sig = (normed_sig - np.mean(normed_sig))/np.std(normed_sig)\n",
    "    return normed_sig\n",
    "\n",
    "def normed_mfcc(file):\n",
    "    normed_sig = normalization(file)\n",
    "    normed_mfcc_feat = librosa.feature.mfcc(normed_sig, 8000, n_mfcc=13)\n",
    "    return normed_mfcc_feat\n",
    "\n",
    "def mfcc_to_npy(folder):\n",
    "\n",
    "    mfcc_vector=[]\n",
    "\n",
    "    for (path, dir, files) in os.walk(folder):\n",
    "        for file in tqdm(files, \"Saving mfcc\"):\n",
    "            if file.endswith(\"wav\"):\n",
    "                normed_mfcc_feat=normed_mfcc(path+file)\n",
    "                mfcc_vector.append(normed_mfcc_feat)\n",
    "\n",
    "    np.save(\"mfcc.npy\", mfcc_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda\n"
    }
   ],
   "source": [
    "#device setting\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "num_epochs=1000\n",
    "learning_rate=0.0001\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "class Accent_dataset(Dataset):\n",
    "    def __init__(self, train = True, transform = None):\n",
    "        label_list = [0, 1, 2]\n",
    "        self.label_accent = ['arabic', 'english', 'spanish']\n",
    "        self.train = train\n",
    "        num_data   =  100\n",
    "        num_train  =  75\n",
    "        num_test   =  25\n",
    "        #onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "        if self.train == True: \n",
    "            self.train_data   =  []\n",
    "            self.train_label  =  []\n",
    "            \n",
    "            print(\"\\n\\n==== Train Data:\")\n",
    "            for item in label_list:\n",
    "                for i in range(1, num_train + 1):\n",
    "                    path = data_path(loc = 'C:/git/download/Accented speech recognition/Accent-Classifier/data/train', \n",
    "                              directory = self.label_accent[item],filename = self.label_accent[item],\n",
    "                              numbering = str(i), format = '.wav')\n",
    "                    mfcc = normed_mfcc(path)\n",
    "                    self.train_data.append(mfcc)\n",
    "                    self.train_label.append(item)\n",
    "                    \n",
    "            self.train_label = np.array(self.train_label)\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape(num_train*3, self.train_data.shape[1], 13) #(90,469,13)\n",
    "\n",
    "            #self.train_label = onehot_encoder.fit_transform(self.train_label.reshape(len(self.train_label), 1)) #(90,3)\n",
    "\n",
    "            self.train_label = torch.cuda.LongTensor(self.train_label)\n",
    "            self.train_data = torch.cuda.FloatTensor(self.train_data)\n",
    "            print(\"=== Dataset Download Complete !!\")\n",
    "            print(\"Shape:\",self.train_data.shape)\n",
    "            print(\"Shape:\",self.train_label.shape)\n",
    "            \n",
    "        else:\n",
    "            self.test_data   =  []\n",
    "            self.test_label  =  []\n",
    "            \n",
    "            print(\"\\n\\n=== Test Data:\")\n",
    "            for item in label_list:\n",
    "                for i in range(num_train + 1, num_data + 1):              \n",
    "                    path = data_path(loc = 'C:/git/download/Accented speech recognition/Accent-Classifier/data/test', \n",
    "                              directory = self.label_accent[item],filename = self.label_accent[item],\n",
    "                                 numbering = str(i), format = '.wav')\n",
    "                    mfcc = normed_mfcc(path)\n",
    "                    self.test_data.append(mfcc)\n",
    "                    self.test_label.append(item)\n",
    "                    \n",
    "            self.test_label = np.array(self.test_label)\n",
    "            self.test_data = np.concatenate(self.test_data)\n",
    "            self.test_data = self.test_data.reshape(num_test*3, self.test_data.shape[1], 13)\n",
    "\n",
    "            #self.test_label = onehot_encoder.fit_transform(self.test_label.reshape(len(self.test_label), 1))\n",
    "            \n",
    "            self.test_label = torch.cuda.LongTensor(self.test_label) \n",
    "            self.test_data = torch.cuda.FloatTensor(self.test_data) \n",
    "            print(\"=== Dataset Download Complete !!\")\n",
    "            print(\"Shape:\",self.test_data.shape)\n",
    "            print(\"Shape:\",self.test_label.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            return self.train_data[index], self.train_label[index]\n",
    "        else:\n",
    "            return self.test_data[index], self.test_label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n==== Test Data:\n=== Dataset Download Complete !!\nShape: torch.Size([30, 469, 13])\ntensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]], device='cuda:0')\ntorch.Size([30, 3])\n"
    }
   ],
   "source": [
    "###dataset test###\n",
    "'''\n",
    "label_list = [0, 1, 2]\n",
    "label_accent = ['arabic', 'english', 'spanish']\n",
    "num_data   =  40\n",
    "num_train  =  30\n",
    "num_test   =  10\n",
    "test_data   =  []\n",
    "test_label  =  []\n",
    "            \n",
    "print(\"\\n\\n==== Test Data:\")\n",
    "for item in label_list:\n",
    "    for i in range(num_train + 1, num_data + 1):\n",
    "        path = data_path(loc = 'C:/git/download/Accented speech recognition/Accent-Classifier/data/test', \n",
    "        directory = label_accent[item],filename = label_accent[item],numbering = str(i), format = '.wav')\n",
    "        mfcc = normed_mfcc(path)\n",
    "        test_data.append(mfcc)\n",
    "        test_label.append(item)\n",
    "                    \n",
    "test_label = np.array(test_label)\n",
    "test_data = np.concatenate(test_data)\n",
    "test_data = test_data.reshape(num_test*3, test_data.shape[1], 13)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "test_label = onehot_encoder.fit_transform(test_label.reshape(len(test_label), 1))\n",
    "\n",
    "test_label = torch.cuda.FloatTensor(test_label) \n",
    "test_data = torch.cuda.FloatTensor(test_data)\n",
    "print(\"=== Dataset Download Complete !!\")\n",
    "print(\"Shape:\",test_data.shape)\n",
    "print(test_label)\n",
    "print(test_label.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n==== Train Data:\n=== Dataset Download Complete !!\nShape: torch.Size([225, 469, 13])\nShape: torch.Size([225])\n\n\n=== Test Data:\n=== Dataset Download Complete !!\nShape: torch.Size([75, 469, 13])\nShape: torch.Size([75])\n"
    }
   ],
   "source": [
    "#dataloader\n",
    "#,transform=transforms.ToTensor()\n",
    "train_dataset = Accent_dataset(train = True)\n",
    "test_dataset = Accent_dataset(train = False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 0, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 0, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#lstm model\n",
    "\n",
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,num_layers):\n",
    "        super(LSTM_model,self).__init__()\n",
    "\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.num_layers=num_layers\n",
    "\n",
    "        self.lstm=nn.LSTM(input_size=self.input_size,hidden_size=self.hidden_size,num_layers=self.num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_().to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_().to(device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "\n",
    "lstm_model=LSTM_model(13,100,3,2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training start\nEpoch    0/1000 Cost: 1.124004\nEpoch  100/1000 Cost: 0.012139\nEpoch  200/1000 Cost: 0.000711\nEpoch  300/1000 Cost: 0.000937\nEpoch  400/1000 Cost: 0.001105\nEpoch  500/1000 Cost: 0.000378\nEpoch  600/1000 Cost: 0.000123\nEpoch  700/1000 Cost: 0.009354\nEpoch  800/1000 Cost: 0.000380\nEpoch  900/1000 Cost: 0.000094\nEpoch 1000/1000 Cost: 0.000031\n"
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "#total_batch = len(train_loader)\n",
    "#avg_cost = 0\n",
    "\n",
    "print(\"Training start\")\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    for train_accent, train_label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_accent=train_accent.to(device)\n",
    "        train_label=train_label.to(device)\n",
    "\n",
    "        hypothesis = lstm_model(train_accent).to(device)\n",
    "        #cost = criterion(hypothesis, torch.max(train_label, 1)[1])\n",
    "        cost = criterion(hypothesis, train_label)\n",
    "\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #avg_cost += cost / total_batch\n",
    "    if epoch % 100 ==0:\n",
    "        print('Epoch: {:4d}/{} Cost: {:.6f}'.format(epoch, num_epochs, cost.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of the model on the testset: 52 %\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_accent, test_label = test_data\n",
    "        #print(test_accent)\n",
    "        #print(test_label)\n",
    "        prediction = lstm_model(test_accent)\n",
    "        #print(prediction)\n",
    "        _, predicted = torch.max(prediction.data, 1)\n",
    "        total += test_label.size(0)\n",
    "        correct += (predicted == test_label).sum().item()\n",
    "\n",
    "print('Accuracy of the model on the testset: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37664bitpytorchcondae7b427a662214bc38094777afdbf6caa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}